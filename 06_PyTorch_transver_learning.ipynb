{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "872981c8-12a1-470e-95d1-cf4320dd2a55",
   "metadata": {},
   "source": [
    "# 06. PyTorch transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d09e14b-3599-432b-8fbc-8d3d5d6d9304",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "print(torch.__version__)\n",
    "print(torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31afd6aa-c42e-49e2-bae2-b1b86138ea42",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from torchinfo import summary\n",
    "except:\n",
    "    print(f\"[INFO] Couldn't found torchinfo... installing it\")\n",
    "    !pip install -q torchinfo\n",
    "    from torchinfo import summary\n",
    "\n",
    "# Try to install Modular dir\n",
    "try:\n",
    "    from going_modular import data_setup, engine\n",
    "except:\n",
    "    print(f\"[INFO] Couldn't found going_modular script... install it.\")\n",
    "    !git clone https://github.com/mrdbourke/pytorch-deep-learning\n",
    "    !mv pytorch-deep-learning/going_modular .\n",
    "    !rm -rf pytorch-deep-learning\n",
    "    from going_modular import data_setup, engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a47718e-c39f-4cb7-b93d-6a7991fc80fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce8db4e-12f2-41e9-b033-579afc00cff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86e4fb8-d543-45b6-85ba-36572eb1639e",
   "metadata": {},
   "source": [
    "## 1. Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f85e95-f425-4e1e-9331-3b2f40b32b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import requests\n",
    "from pathlib import Path\n",
    "\n",
    "data_path = Path(\"data_06/\")\n",
    "image_path = data_path / \"pizza_steak_sushi\"\n",
    "\n",
    "if image_path.is_dir():\n",
    "    print(f\"{image_path} directory axists.\")\n",
    "else:\n",
    "    print(f\"Didn't found {image_path} downloding it\")\n",
    "    image_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    with open(data_path / \"pizza_steak_sushi.zip\", \"wb\") as f:\n",
    "        request = requests.get(\"https://github.com/mrdbourke/pytorch-deep-learning/raw/refs/heads/main/data/pizza_steak_sushi.zip\")\n",
    "        print(f\"Downloading....\")\n",
    "        f.write(request.content)\n",
    "\n",
    "    # Unzip data\n",
    "    with zipfile.ZipFile(data_path / \"pizza_steak_sushi.zip\", \"r\") as zip_ref:\n",
    "        print(f\"Unziooing file....\")\n",
    "        zip_ref.extractall(image_path)\n",
    "    # Remove Zip file\n",
    "    os.remove(data_path / \"pizza_steak_sushi.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a37fbe-116b-441a-95ab-25efbd35da55",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = image_path / \"train\"\n",
    "test_dir = image_path / \"test\"\n",
    "\n",
    "train_dir, test_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32548008-5491-4136-b03a-4ae4bbe1e3e5",
   "metadata": {},
   "source": [
    "## 2. Creating transform for `torchvision.models`\n",
    "* All pre-trained models expect input images normalized in the same way, i.e. mini-batches of 3-channel RGB images of shape (3 x H x W), where H and W are expected to be at least 224.\n",
    "The images have to be loaded in to a range of [0, 1] and then normalized using mean = [0.485, 0.456, 0.406] and std = [0.229, 0.224, 0.225]."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13aa37d-97a1-4cf6-84c1-56bd43a8386a",
   "metadata": {},
   "source": [
    "### 2.1 Manual creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0720efc4-231c-4a43-a901-3d905420683f",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                std=[0.229, 0.224, 0.225])\n",
    "manual_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    normalize]) # make sure images have the same distribution as ImageNet (where our pretrained mopdels have been trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445fe6aa-ab1b-4810-81e4-297888ac4ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader, test_dataloader, class_names = data_setup.create_dataloader(train_dir=train_dir, test_dir=test_dir, transforms=manual_transforms, batch_size=32)\n",
    "train_dataloader, test_dataloader, class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d831695b-45dc-4f6b-af77-2eddb4a85cc0",
   "metadata": {},
   "source": [
    "### 2.2 Auto transform creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66dfee99-8783-48bc-afe1-ace46f4820cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a set of preptrained model weights\n",
    "weights = torchvision.models.EfficientNet_B0_Weights.DEFAULT # DEFAULT = best avalileble weights\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b941f2be-16b6-4122-929d-3ada77fdd708",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get transfroms used to create our pretrained weights\n",
    "auto_transfroms = weights.transforms()\n",
    "auto_transfroms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66188e30-0aa1-42d6-8c47-5c71e7ae3418",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloder, test_datalodear, class_names = data_setup.create_dataloader(train_dir=train_dir, test_dir=test_dir, transforms=auto_transfroms, batch_size=32)\n",
    "train_dataloader, test_dataloader, class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd44a34-ea65-430b-85ef-2b26c4098e78",
   "metadata": {},
   "source": [
    "## 3. Getting pretrain modle\n",
    "\n",
    "1. PyTorch main libraries\n",
    "2. Libraries like `timm` (torch image models)\n",
    "3. HoggingFase Hub\n",
    "4. Paperswithcode "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40e98f8-be5c-49d9-aebe-d3294d215531",
   "metadata": {},
   "source": [
    "### 3.1 Creating of a pretrained EffNet_B0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e08849-600e-4449-be4c-fec00dc9d376",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aceff6bd-2617-421c-961c-7c9ca001dc9e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = torchvision.models.efficientnet_b0(weights=weights)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c812adb-65f5-45bc-9d8e-e9663f57cc3d",
   "metadata": {},
   "source": [
    "### 3.2 Get summary of our model with `torchinfo.summary()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c171fc-29bf-402f-a018-b377d25011c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(model=model, \n",
    "        input_size=(1, 3, 224, 224), \n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"], \n",
    "        col_width=20, \n",
    "        row_settings=[\"var_names\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a67574a-b4ee-47cb-89ac-c244f8a6bfe2",
   "metadata": {},
   "source": [
    "### 3.3 Freezing the base model and changing the outup layer to suit our needs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d00846-3321-4ff8-aa62-751bfa1e5b3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b87780-a516-4756-b5a3-1b30fd4da335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freez all of the base layers in EffNeB0\n",
    "for param in model.features.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3ee3ed-0f34-42d3-acd1-e309ef5f47b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updae the classifier head of our model to suit our problem\n",
    "model.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d665d8-3a77-465e-949b-a22b5637f964",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.classifier = nn.Sequential(\n",
    "    nn.Dropout(p=0.2, inplace=True),\n",
    "    nn.Linear(in_features=1280, out_features=len(class_names)))\n",
    "\n",
    "model.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ae51a0-9c3b-42d3-b9d7-e7f4f5406ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(model=model, \n",
    "        input_size=(1, 3, 224, 224), \n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"], \n",
    "        col_width=20, \n",
    "        row_settings=[\"var_names\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ab8ced-93fa-40c5-9190-6fdb24c8d6b8",
   "metadata": {},
   "source": [
    "## 4 Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e9b54b-1b0b-43e8-b0fa-fccfadcc5847",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdac0065-d406-4ff1-a669-b91455180190",
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer\n",
    "\n",
    "start_time = timer()\n",
    "results = engine.train(model=model, \n",
    "                       train_dataloader=train_dataloader,\n",
    "                       test_dataloader=test_datalodear,\n",
    "                       loss_fn=loss_fn,\n",
    "                       optimizer=optimizer,\n",
    "                       epochs=5)\n",
    "end_time = timer()\n",
    "print(f\"Total time: {end_time - start_time:.1f}. seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0772a047-bb2e-4c92-88ae-c08f0b261581",
   "metadata": {},
   "source": [
    "## 5. Evaluate model by Plotting loss curves "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcc6224-cc64-473a-bcb0-814a653aaaab",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from helper_function import plot_loss_curves\n",
    "except:\n",
    "    print(f\"Couldn't find helper_function.py, downloading...\")\n",
    "    with open(\"helper_function.py\", \"wb\") as f:\n",
    "        request = requests.get(\"https://github.com/mrdbourke/pytorch-deep-learning/raw/refs/heads/main/helper_functions.py\")\n",
    "        f.write(request.contest)\n",
    "    from helper_function import plot_loss_curves\n",
    "\n",
    "plot_loss_curves(results=results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7aed46-5b5e-40f6-b7af-026fa4532836",
   "metadata": {},
   "source": [
    "## 6. Make predictions on images from the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae5ad87-f3b6-42d6-b301-f61bea6e1cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb82098c-c6f2-4ade-b5a6-9fb1cdae7cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Tuple\n",
    "from PIL import Image\n",
    "\n",
    "# 1. Take in a trained model...\n",
    "def pred_and_plot_imge(model: torch.nn.Module,\n",
    "                       img_path: str,\n",
    "                       class_names: List[str],\n",
    "                       image_size: Tuple[int, int] = (224, 224),\n",
    "                       transform: torchvision.transforms = None,\n",
    "                       device: torch.device = device):\n",
    "    # 2. Open Image with PIL\n",
    "    img = Image.open(img_path)\n",
    "\n",
    "    # 3. Creat a transform\n",
    "    if transform is not None:\n",
    "        image_transform = transform\n",
    "    else:\n",
    "        image_transform = transforms.Compose([\n",
    "            transforms.Resize(image_size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "   \n",
    "    model.to(device)\n",
    "\n",
    "    # 4. Turn on inference_mode and eval mode\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        transformed_image = image_transform(img).unsqueeze(dim=0) # [batch_size, color_channales, H, W]\n",
    "        traget_image_pred = model(transformed_image.to(device))\n",
    "        \n",
    "    target_image_pred_probs = torch.softmax(traget_image_pred, dim=1)\n",
    "    target_imge_label = torch.argmax(target_image_pred_probs, dim=1)\n",
    "    # 5 Plot image\n",
    "    plt.figure()\n",
    "    plt.imshow(img)\n",
    "    plt.title(f\"Pred: {class_names[target_imge_label]} | Prob: {target_image_pred_probs.max():.3f}\")\n",
    "    plt.axis(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c36895-9655-49b7-917c-902656115e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "num_images = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b00763f-c742-429b-a1bb-6d80212dcbb3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_images_path_list = list(Path(test_dir).glob(\"*/*.jpg\"))\n",
    "test_images_path_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d678049e-4e87-4527-bd8b-d25f46f3f533",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_path_random = random.sample(population=test_images_path_list, k=num_images)\n",
    "test_image_path_random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668ae8b0-0435-4913-ac07-6af84714dca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for img in test_image_path_random:\n",
    "    pred_and_plot_imge(model=model,\n",
    "                       img_path=img,\n",
    "                       class_names=class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ab4ec6-4ff0-4d9d-93f1-22b875169849",
   "metadata": {},
   "source": [
    "### 6.1 Custom image Prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733aacb4-5d55-4c15-b112-d21cbc4356da",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_image_path = data_path / \"04-pizza-dad.jpeg\"\n",
    "\n",
    "if not custom_image_path.is_file():\n",
    "    with open(custom_image_path, \"wb\") as f:\n",
    "        request = requests.get(\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/images/04-pizza-dad.jpeg\")\n",
    "        f.write(request.content)\n",
    "else:\n",
    "    print(f\"{custom_image_path} alredy exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c566e12-b57e-4598-9376-1f953c72fefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_and_plot_imge(model=model,\n",
    "                   img_path=custom_image_pathe,\n",
    "                   class_names=class_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
